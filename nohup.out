INFO:     Will watch for changes in these directories: ['/home/jovyan/AgentChain']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [162460] using StatReload
 * Ngrok public URL: NgrokTunnel: "https://121a-203-253-159-19.ngrok-free.app" -> "http://localhost:8000"
/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/lib/nvidia')}
  warn(msg)
Form data requires "python-multipart" to be installed. 
You can install "python-multipart" with: 

pip install python-multipart


===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/jovyan/AgentChain/venv/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so
CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/jovyan/AgentChain/venv/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
Process SpawnProcess-1:
Traceback (most recent call last):
  File "/usr/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/lib/python3.8/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/lib/python3.8/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1014, in _gcd_import
  File "<frozen importlib._bootstrap>", line 991, in _find_and_load
  File "<frozen importlib._bootstrap>", line 975, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 671, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 848, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/home/jovyan/AgentChain/app.py", line 58, in <module>
    async def finetune_model(
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/fastapi/routing.py", line 704, in decorator
    self.add_api_route(
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/fastapi/routing.py", line 643, in add_api_route
    route = route_class(
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/fastapi/routing.py", line 495, in __init__
    self.body_field = get_body_field(dependant=self.dependant, name=self.unique_id)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/fastapi/dependencies/utils.py", line 801, in get_body_field
    check_file_field(final_field)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/fastapi/dependencies/utils.py", line 100, in check_file_field
    raise RuntimeError(multipart_not_installed_error) from None
RuntimeError: Form data requires "python-multipart" to be installed. 
You can install "python-multipart" with: 

pip install python-multipart

t=2025-05-20T01:26:39+0000 lvl=warn msg="can't bind default web address, trying alternatives" obj=web addr=127.0.0.1:4040
ERROR:  authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.
ERROR:  You can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.
ERROR:  Read more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config
ERROR:  You can view your current agent sessions in the dashboard:
ERROR:  https://dashboard.ngrok.com/agents
ERROR:  
ERROR:  ERR_NGROK_108
ERROR:  https://ngrok.com/docs/errors/err_ngrok_108
ERROR:  
t=2025-05-20T01:26:40+0000 lvl=eror msg="failed to reconnect session" obj=tunnels.session err="authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\nYou can view your current agent sessions in the dashboard:\nhttps://dashboard.ngrok.com/agents\r\n\r\nERR_NGROK_108\r\n"
t=2025-05-20T01:26:40+0000 lvl=eror msg="session closing" obj=tunnels.session err="authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\nYou can view your current agent sessions in the dashboard:\nhttps://dashboard.ngrok.com/agents\r\n\r\nERR_NGROK_108\r\n"
Traceback (most recent call last):
  File "run_with_ngrok.py", line 12, in <module>
    public_url = ngrok.connect(port)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/pyngrok/ngrok.py", line 385, in connect
    api_url = get_ngrok_process(pyngrok_config).api_url
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/pyngrok/ngrok.py", line 203, in get_ngrok_process
    return process.get_process(pyngrok_config)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/pyngrok/process.py", line 270, in get_process
    return _start_process(pyngrok_config)
  File "/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/pyngrok/process.py", line 447, in _start_process
    raise PyngrokNgrokError(f"The ngrok process errored on start: {ngrok_process.startup_error}.",
pyngrok.exception.PyngrokNgrokError: The ngrok process errored on start: authentication failed: Your account is limited to 1 simultaneous ngrok agent sessions.\nYou can run multiple simultaneous tunnels from a single agent session by defining the tunnels in your agent configuration file and starting them with the command `ngrok start --all`.\nRead more about the agent configuration file: https://ngrok.com/docs/secure-tunnels/ngrok-agent/reference/config\nYou can view your current agent sessions in the dashboard:\nhttps://dashboard.ngrok.com/agents\r\n\r\nERR_NGROK_108\r\n.
t=2025-05-20T01:27:17+0000 lvl=warn msg="Stopping forwarder" name=http-8000-55d65540-eb15-4921-a196-5cde96303df8 acceptErr="failed to accept connection: Listener closed"
t=2025-05-20T01:27:17+0000 lvl=warn msg="Error restarting forwarder" name=http-8000-55d65540-eb15-4921-a196-5cde96303df8 err="failed to start tunnel: session closed"
INFO:     Will watch for changes in these directories: ['/home/jovyan/AgentChain']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [162984] using StatReload
 * Ngrok public URL: NgrokTunnel: "https://a24a-203-253-159-19.ngrok-free.app" -> "http://localhost:8000"
/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/lib/nvidia')}
  warn(msg)
INFO:     Started server process [163032]
INFO:     Waiting for application startup.
INFO:     Application startup complete.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/jovyan/AgentChain/venv/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so
CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.6
CUDA SETUP: Detected CUDA version 113
CUDA SETUP: Loading binary /home/jovyan/AgentChain/venv/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda113.so...
INFO:     211.235.89.186:0 - "GET /models HTTP/1.1" 200 OK
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /home/jovyan/AgentChain/models/llama3.2_1b and are newly initialized: ['lm_head.weight', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers
pip install xformers.
INFO:     211.235.89.186:0 - "POST /generate?model_name=llama3.2_1b HTTP/1.1" 500 Internal Server Error
INFO:     211.235.89.186:0 - "POST /generate?model_name=meta-llamaLlama-3.2-3B_koalpaca HTTP/1.1" 500 Internal Server Error
INFO:     211.235.89.186:0 - "POST /generate?model_name=meta-llamaLlama-3.2-3B_koalpaca HTTP/1.1" 500 Internal Server Error
INFO:     211.235.89.186:0 - "POST /generate?model_name=llama3.2_1b HTTP/1.1" 500 Internal Server Error
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.77s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /home/jovyan/AgentChain/models/meta-llamaLlama-3.2-3B and are newly initialized: ['model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'lm_head.weight', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
INFO:     211.235.89.186:0 - "POST /generate?model_name=meta-llamaLlama-3.2-3B HTTP/1.1" 500 Internal Server Error
INFO:     211.235.89.186:0 - "POST /finetune HTTP/1.1" 200 OK
/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.50s/it]
Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /home/jovyan/AgentChain/models/meta-llamaLlama-3.2-3B and are newly initialized: ['model.layers.20.self_attn.rotary_emb.inv_freq', 'model.layers.5.self_attn.rotary_emb.inv_freq', 'model.layers.8.self_attn.rotary_emb.inv_freq', 'model.layers.15.self_attn.rotary_emb.inv_freq', 'model.layers.6.self_attn.rotary_emb.inv_freq', 'model.layers.14.self_attn.rotary_emb.inv_freq', 'model.layers.4.self_attn.rotary_emb.inv_freq', 'model.layers.21.self_attn.rotary_emb.inv_freq', 'model.layers.26.self_attn.rotary_emb.inv_freq', 'model.layers.19.self_attn.rotary_emb.inv_freq', 'model.layers.24.self_attn.rotary_emb.inv_freq', 'model.layers.27.self_attn.rotary_emb.inv_freq', 'model.layers.23.self_attn.rotary_emb.inv_freq', 'model.layers.0.self_attn.rotary_emb.inv_freq', 'model.layers.17.self_attn.rotary_emb.inv_freq', 'model.layers.11.self_attn.rotary_emb.inv_freq', 'model.layers.3.self_attn.rotary_emb.inv_freq', 'model.layers.22.self_attn.rotary_emb.inv_freq', 'model.layers.12.self_attn.rotary_emb.inv_freq', 'lm_head.weight', 'model.layers.9.self_attn.rotary_emb.inv_freq', 'model.layers.16.self_attn.rotary_emb.inv_freq', 'model.layers.2.self_attn.rotary_emb.inv_freq', 'model.layers.7.self_attn.rotary_emb.inv_freq', 'model.layers.25.self_attn.rotary_emb.inv_freq', 'model.layers.1.self_attn.rotary_emb.inv_freq', 'model.layers.18.self_attn.rotary_emb.inv_freq', 'model.layers.10.self_attn.rotary_emb.inv_freq', 'model.layers.13.self_attn.rotary_emb.inv_freq']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Using pad_token, but it is not set yet.
/home/jovyan/AgentChain/venv/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
  0%|          | 0/3 [00:00<?, ?it/s]You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 0/3 [00:01<?, ?it/s]INFO:     211.235.89.186:0 - "GET /finetune-status/meta-llamaLlama-3.2-3B_custom_model HTTP/1.1" 200 OK
INFO:     1.234.192.13:0 - "GET /finetune-status/meta-llamaLlama-3.2-3B_koalpaca HTTP/1.1" 200 OK
INFO:     1.234.192.13:0 - "GET /models HTTP/1.1" 200 OK
INFO:     1.234.192.13:0 - "POST /generate?model_name=meta-llamaLlama-3.2-3B HTTP/1.1" 500 Internal Server Error
